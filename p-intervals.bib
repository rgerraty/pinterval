
@article{open_science_collaboration_estimating_2015,
	title = {Estimating the reproducibility of psychological},
	volume = {349},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/content/349/6251/aac4716},
	doi = {10.1126/science.aac4716},
	abstract = {Empirically analyzing empirical evidence
One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.},
	pages = {aac4716},
	number = {6251},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Open Science Collaboration},
	urldate = {2015-09-08},
	date = {2015-08-28},
	langid = {english},
	pmid = {26315443},
	note = {00000 },
	file = {Full Text PDF:/Users/Matti/Dropbox/academia/zotero/storage/Z93R6RWM/Collaboration - 2015 - Estimating the reproducibility of psychological.pdf:application/pdf;Snapshot:/Users/Matti/Dropbox/academia/zotero/storage/QJIMIRV8/aac4716.html:text/html}
}

@article{spellman_short_2015,
	title = {A Short (Personal) Future History of Revolution 2.0},
	volume = {10},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/10/6/886},
	doi = {10.1177/1745691615609918},
	abstract = {Crisis of replicability is one term that psychological scientists use for the current introspective phase we are in—I argue instead that we are going through a revolution analogous to a political revolution. Revolution 2.0 is an uprising focused on how we should be doing science now (i.e., in a 2.0 world). The precipitating events of the revolution have already been well-documented: failures to replicate, questionable research practices, fraud, etc. And the fact that none of these events is new to our field has also been well-documented. I suggest four interconnected reasons as to why this time is different: changing technology, changing demographics of researchers, limited resources, and misaligned incentives. I then describe two reasons why the revolution is more likely to catch on this time: technology (as part of the solution) and the fact that these concerns cut across social and life sciences—that is, we are not alone. Neither side in the revolution has behaved well, and each has characterized the other in extreme terms (although, of course, each has had a few extreme actors). Some suggested reforms are already taking hold (e.g., journals asking for more transparency in methods and analysis decisions; journals publishing replications) but the feared tyrannical requirements have, of course, not taken root (e.g., few journals require open data; there is no ban on exploratory analyses). Still, we have not yet made needed advances in the ways in which we accumulate, connect, and extract conclusions from our aggregated research. However, we are now ready to move forward by adopting incremental changes and by acknowledging the multiplicity of goals within psychological science.},
	pages = {886--899},
	number = {6},
	journaltitle = {Perspectives on Psychological Science},
	shortjournal = {Perspectives on Psychological Science},
	author = {Spellman, Barbara A.},
	urldate = {2015-11-18},
	date = {2015-11-01},
	langid = {english},
	note = {00000},
	keywords = {journal practices, Methodology, replication, scientific practices},
	file = {Full Text PDF:/Users/Matti/Dropbox/academia/zotero/storage/VG64RCM5/Spellman - 2015 - A Short (Personal) Future History of Revolution 2..pdf:application/pdf;Snapshot:/Users/Matti/Dropbox/academia/zotero/storage/562DX793/886.html:text/html}
}

@article{morey_continued_2015,
	title = {Continued misinterpretation of confidence intervals: response to Miller and Ulrich},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/article/10.3758/s13423-015-0955-8},
	doi = {10.3758/s13423-015-0955-8},
	shorttitle = {Continued misinterpretation of confidence intervals},
	abstract = {Miller and Ulrich (2015) critique our claim (Hoekstra et al., Psychonomic Bulletin \& Review, 21(5), 1157–1164, 2014), based on a survey given to researchers and students, of widespread misunderstanding of confidence intervals ({CIs}). They suggest that survey respondents may have interpreted the statements in the survey that we deemed incorrect in an idiosyncratic, but correct, way, thus calling into question the conclusion that the results indicate that respondents could not properly interpret {CIs}. Their alternative interpretations, while correct, cannot be deemed acceptable renderings of the questions in the survey due to the well-known reference class problem. Moreover, there is no support in the data for their contention that participants may have had their alternative interpretations in mind. Finally, their alternative interpretations are merely trivial restatements of the definition of a confidence interval, and have no implications for the location of a parameter.},
	pages = {1--10},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychon Bull Rev},
	author = {Morey, Richard D. and Hoekstra, Rink and Rouder, Jeffrey N. and Wagenmakers, Eric-Jan},
	urldate = {2015-12-09},
	date = {2015-11-30},
	langid = {english},
	note = {00000},
	keywords = {Bayesian statistics, Cognitive Psychology, statistical inference, statistics},
	file = {Full Text PDF:/Users/Matti/Dropbox/academia/zotero/storage/NN7PFX25/Morey et al. - 2015 - Continued misinterpretation of confidence interval.pdf:application/pdf;Snapshot:/Users/Matti/Dropbox/academia/zotero/storage/NM2527RE/s13423-015-0955-8.html:text/html}
}

@article{morey_fallacy_2015,
	title = {The fallacy of placing confidence in confidence intervals},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/article/10.3758/s13423-015-0947-8},
	doi = {10.3758/s13423-015-0947-8},
	abstract = {Interval estimates – estimates of parameters that include an allowance for sampling uncertainty – have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals ({CIs}): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; {CIs} are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 \%) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that {CIs} do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.},
	pages = {1--21},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychon Bull Rev},
	author = {Morey, Richard D. and Hoekstra, Rink and Rouder, Jeffrey N. and Lee, Michael D. and Wagenmakers, Eric-Jan},
	urldate = {2015-12-09},
	date = {2015-10-08},
	langid = {english},
	note = {00004},
	keywords = {Bayesian inference and parameter estimation, Bayesian statistics, Cognitive Psychology, statistical inference, statistics},
	file = {Full Text PDF:/Users/Matti/Dropbox/academia/zotero/storage/TJICB8TJ/Morey et al. - 2015 - The fallacy of placing confidence in confidence in.pdf:application/pdf;Snapshot:/Users/Matti/Dropbox/academia/zotero/storage/HQ7FVRJW/10.html:text/html}
}

@online{gelman_statistical_2011,
	title = {The statistical significance filter},
	url = {http://andrewgelman.com/2011/09/10/the-statistical-significance-filter/},
	abstract = {I’ve talked about this a bit but it’s never had its own blog entry (until now). Statistically significant findings tend to overestimate the magnitude of effects. This holds in general (because E({\textbar}x{\textbar}) {\textgreater} {\textbar}E(x){\textbar}) but even more so if you restrict to statistically significant results. Here’s an example. Suppose a true effect of theta is …},
	titleaddon = {Statistical Modeling, Causal Inference, and Social Science},
	author = {Gelman, Andrew},
	urldate = {2015-12-09},
	date = {2011-10-09},
	note = {00000},
	file = {Snapshot:/Users/Matti/Dropbox/academia/zotero/storage/VM7RERD9/the-statistical-significance-filter.html:text/html}
}

@article{cohen_earth_1994,
	title = {The earth is round ({\textless} em{\textgreater} p{\textless}/em{\textgreater}{\textless}. 05).},
	volume = {49},
	url = {http://psycnet.apa.org/journals/amp/49/12/997/},
	pages = {997},
	number = {12},
	journaltitle = {American psychologist},
	author = {Cohen, Jacob},
	urldate = {2014-12-23},
	date = {1994},
	keywords = {Statistics},
	file = {Cohen 1994.pdf:/Users/Matti/Dropbox/academia/zotero/storage/AHZTU7N3/Cohen 1994.pdf:application/pdf}
}

@article{cumming_new_2014,
	title = {The New Statistics Why and How},
	volume = {25},
	issn = {0956-7976, 1467-9280},
	url = {http://pss.sagepub.com/content/25/1/7},
	doi = {10.1177/0956797613504966},
	abstract = {We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate data-analytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing ({NHST}), we need to shift from reliance on {NHST} to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for {NHST}, and is aimed at building a cumulative quantitative discipline.},
	pages = {7--29},
	number = {1},
	journaltitle = {Psychological Science},
	shortjournal = {Psychological Science},
	author = {Cumming, Geoff},
	urldate = {2015-05-12},
	date = {2014-01-01},
	langid = {english},
	pmid = {24220629},
	note = {00000 },
	keywords = {estimation, meta-analysis, replication, research integrity, research methods, statistical analysis, the new statistics},
	file = {Full Text PDF:/Users/Matti/Dropbox/academia/zotero/storage/GDTMN5FZ/Cumming - 2014 - The New Statistics Why and How.pdf:application/pdf;Snapshot:/Users/Matti/Dropbox/academia/zotero/storage/KH5DW4IB/7.html:text/html}
}

@article{krantz_null_1999,
	title = {The Null Hypothesis Testing Controversy in Psychology},
	volume = {94},
	rights = {Copyright © 1999 American Statistical Association},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2669949},
	doi = {10.2307/2669949},
	abstract = {A controversy concerning the usefulness of "null" hypothesis tests in scientific inference has continued in articles within psychology since 1960 and has recently come to a head, with serious proposals offered for a test ban or something close to it. This article sketches some of the views of statistical theory and practice among different groups of psychologists, reviews a recent book offering multiple perspectives on null hypothesis tests, and argues that the debate within psychology is a symptom of serious incompleteness in the foundations of statistics.},
	pages = {1372--1381},
	number = {448},
	journaltitle = {Journal of the American Statistical Association},
	shortjournal = {Journal of the American Statistical Association},
	author = {Krantz, David H.},
	urldate = {2015-08-05},
	date = {1999-12-01},
	note = {00000},
	keywords = {Null hypothesis significance testing, Statistics},
	file = {JSTOR Full Text PDF:/Users/Matti/Dropbox/academia/zotero/storage/SB57BSMA/Krantz - 1999 - The Null Hypothesis Testing Controversy in Psychol.pdf:application/pdf}
}

@article{gelman_statistical_2014,
	title = {The Statistical Crisis in Science},
	volume = {102},
	issn = {0003-0996, 1545-2786},
	url = {http://www.americanscientist.org/issues/feature/2014/6/the-statistical-crisis-in-science},
	doi = {10.1511/2014.111.460},
	pages = {460},
	number = {6},
	journaltitle = {American Scientist},
	author = {Gelman, Andrew and Loken, Eric},
	urldate = {2015-08-06},
	date = {2014},
	langid = {english},
	note = {00000},
	keywords = {bayesian statistics, science, Statistics},
	file = {ForkingPaths.pdf:/Users/Matti/Dropbox/academia/zotero/storage/3ZQ3CFMF/ForkingPaths.pdf:application/pdf}
}